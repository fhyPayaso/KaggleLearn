{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# LightGBM\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# sklearn tools for model training and assesment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (roc_curve, auc, accuracy_score)\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainRaw = pd.read_csv('./train.csv')\n",
    "testRaw = pd.read_csv('./test.csv')\n",
    "\n",
    "# And concatonate together\n",
    "nTrain = trainRaw.shape[0]\n",
    "full = pd.concat([trainRaw, testRaw], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 1309 entries, 0 to 417\nData columns (total 12 columns):\nAge            1046 non-null float64\nCabin          295 non-null object\nEmbarked       1307 non-null object\nFare           1308 non-null float64\nName           1309 non-null object\nParch          1309 non-null int64\nPassengerId    1309 non-null int64\nPclass         1309 non-null int64\nSex            1309 non-null object\nSibSp          1309 non-null int64\nSurvived       891 non-null float64\nTicket         1309 non-null object\ndtypes: float64(3), int64(4), object(5)\nmemory usage: 132.9+ KB\n"
    }
   ],
   "source": [
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Age Cabin Embarked     Fare  \\\n0  22.0   NaN        S   7.2500   \n1  38.0   C85        C  71.2833   \n2  26.0   NaN        S   7.9250   \n3  35.0  C123        S  53.1000   \n4  35.0   NaN        S   8.0500   \n\n                                                Name  Parch  PassengerId  \\\n0                            Braund, Mr. Owen Harris      0            1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \n2                             Heikkinen, Miss. Laina      0            3   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \n4                           Allen, Mr. William Henry      0            5   \n\n   Pclass     Sex  SibSp  Survived            Ticket  \n0       3    male      1       0.0         A/5 21171  \n1       1  female      1       1.0          PC 17599  \n2       3  female      0       1.0  STON/O2. 3101282  \n3       1  female      1       1.0            113803  \n4       3    male      0       0.0            373450  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Fare</th>\n      <th>Name</th>\n      <th>Parch</th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>SibSp</th>\n      <th>Survived</th>\n      <th>Ticket</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>7.2500</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>male</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>A/5 21171</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38.0</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>71.2833</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>female</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>PC 17599</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26.0</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>7.9250</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>female</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>STON/O2. 3101282</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35.0</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>53.1000</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>female</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>113803</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>8.0500</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>0</td>\n      <td>5</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>373450</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cabins\n",
    "def ADSplit(s):\n",
    "    \"\"\"\n",
    "    Function to try and extract cabin letter and number from the cabin column.\n",
    "    Runs a regular expression that finds letters and numbers in the\n",
    "    string. These are held in match.group, if they exist.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"([a-z]+)([0-9]+)\", s, re.I)\n",
    "    try:\n",
    "        letter = match.group(1)\n",
    "    except:\n",
    "        letter = ''\n",
    "\n",
    "    try:\n",
    "        number = match.group(2)\n",
    "    except:\n",
    "        number = 9999\n",
    "\n",
    "    return letter, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DR(s):\n",
    "    \"\"\"\n",
    "    From the cabin string, try and extract letter, number, and number of cabins\n",
    "    \"\"\"\n",
    "    # Check contents\n",
    "    if isinstance(s, (int, float)):\n",
    "        # If field is empty, return nothing\n",
    "        letter = ''\n",
    "        number = ''\n",
    "        nRooms = 9999\n",
    "    else:\n",
    "        # If field isn't empty, split sting on space. Some strings contain\n",
    "        # multiple cabins.\n",
    "        s = s.split(' ')\n",
    "        # Count the cabins based on number of splits\n",
    "        nRooms = len(s)\n",
    "        # Just take first cabin for letter/number extraction\n",
    "        s = s[0]\n",
    "\n",
    "        letter, number = ADSplit(s)\n",
    "\n",
    "    return [letter, number, nRooms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DR function to each cell in Cabin column using pandas apply method.\n",
    "out = full['Cabin'].apply(DR)\n",
    "# Outout tuple with 3 values for each row, convert this to pandas df\n",
    "out = out.apply(pd.Series)\n",
    "# And name the columns\n",
    "out.columns = ['CL', 'CN', 'nC']\n",
    "\n",
    "# Then concatenate these columns to the dataset\n",
    "full = pd.concat([full, out], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Family\n",
    "# Add some family features directly to new columns in the dataset\n",
    "\n",
    "# Size\n",
    "full['fSize'] = full['SibSp'] + full['Parch'] + 1\n",
    "# Ratio\n",
    "full['fRatio'] = (full['Parch'] + 1) / (full['SibSp'] + 1)\n",
    "# Adult?\n",
    "full['Adult'] = full['Age'] > 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Names\n",
    "\n",
    "# Extract titles from Name column, standardise\n",
    "titleDict = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Sir\",\n",
    "    \"Don\": \"Sir\",\n",
    "    \"Sir\": \"Sir\",\n",
    "    \"Dr\": \"Dr\",\n",
    "    \"Rev\": \"Rev\",\n",
    "    \"theCountess\": \"Lady\",\n",
    "    \"Dona\": \"Lady\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\": \"Mr\",\n",
    "    \"Mrs\": \"Mrs\",\n",
    "    \"Miss\": \"Miss\",\n",
    "    \"Master\": \"Master\",\n",
    "    \"Lady\": \"Lady\"\n",
    "}\n",
    "\n",
    "\n",
    "def splitName(s, titleDict):\n",
    "    \"\"\"\n",
    "    Extract title from name, replace with value in title dictionary. Also\n",
    "    return surname.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove '.' from name string\n",
    "    s = s.replace('.', '')\n",
    "    # Split on spaces\n",
    "    s = s.split(' ')\n",
    "    # get surname\n",
    "    surname = s[0]\n",
    "\n",
    "    # Get title - loop over titleDict, if s matches a key, take the\n",
    "    # corresponding value as the title\n",
    "    title = [t for k, t in titleDict.items() if str(k) in s]\n",
    "\n",
    "    # If no matching keys in title dict, use 'Other'.\n",
    "    if title == []:\n",
    "        title = 'Other'\n",
    "    else:\n",
    "        # Title is a list, so extract contents\n",
    "        title = title[0]\n",
    "\n",
    "    # Return surname (stripping remaining ',') and title as string\n",
    "    return surname.strip(','), title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions to df and concatenate new columns as before\n",
    "out = full['Name'].apply(splitName,\n",
    "                         args=[titleDict])\n",
    "out = out.apply(pd.Series)\n",
    "out.columns = ['Surname', 'Title']\n",
    "\n",
    "full = pd.concat([full, out], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Categorical columns\n",
    "# List of categorical columns to recode\n",
    "catCols = ['Sex', 'Embarked', 'CL', 'CN', 'Surname', 'Title']\n",
    "\n",
    "# Recode\n",
    "for c in catCols:\n",
    "    # Convert column to pd.Categotical\n",
    "    full[c] = pd.Categorical(full[c])\n",
    "    # Extract the cat.codes and replace the column with these\n",
    "    full[c] = full[c].cat.codes\n",
    "    # Convert the cat codes to categotical...\n",
    "    full[c] = pd.Categorical(full[c])\n",
    "\n",
    "\n",
    "# Generate a logical index of categorical columns to maybe use with LightGBM later\n",
    "catCols = [i for i,v in enumerate(full.dtypes) if str(v)=='category']\n",
    "\n",
    "\n",
    "#%% Age\n",
    "# Replace missing age values with median.\n",
    "# See ither kernels for more sophisticated ways of doing this!\n",
    "full.loc[full.Age.isnull(), 'Age'] = np.median(full['Age'].loc[full.Age.notnull()])\n",
    "\n",
    "#%% Split datasets\n",
    "train = full.iloc[0:nTrain,:]\n",
    "test = full.iloc[nTrain::,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Prepare data\n",
    "def prepLGB(data,\n",
    "            classCol='',\n",
    "            IDCol='',\n",
    "            fDrop=[]):\n",
    "\n",
    "        # Drop class column\n",
    "        if classCol != '':\n",
    "            labels = data[classCol]\n",
    "            fDrop = fDrop + [classCol]\n",
    "        else:\n",
    "            labels = []\n",
    "\n",
    "        if IDCol != '':\n",
    "            IDs = data[IDCol]\n",
    "        else:\n",
    "            IDs = []\n",
    "\n",
    "        if fDrop != []:\n",
    "           data = data.drop(fDrop,\n",
    "                            axis=1)\n",
    "\n",
    "        # Create LGB mats\n",
    "        lData = lgb.Dataset(data, label=labels,\n",
    "                            free_raw_data=False,\n",
    "                            feature_name=list(data.columns),\n",
    "                            categorical_feature='auto')\n",
    "\n",
    "        return lData, labels, IDs, data\n",
    "\n",
    "\n",
    "# Specify columns to drop\n",
    "fDrop = ['Ticket', 'Cabin', 'Name']\n",
    "\n",
    "# Split training data in to training and validation sets.\n",
    "# Validation set is used for early stopping.\n",
    "trainData, validData = train_test_split(train,\n",
    "                                        test_size=0.3,\n",
    "                                        stratify=train.Survived)\n",
    "\n",
    "# Prepare the data sets\n",
    "trainDataL, trainLabels, trainIDs, trainData = prepLGB(trainData,\n",
    "                                                 classCol='Survived',\n",
    "                                                 IDCol='PassengerId',\n",
    "                                                 fDrop=fDrop)\n",
    "\n",
    "validDataL, validLabels, validIDs, validData = prepLGB(validData,\n",
    "                                                 classCol='Survived',\n",
    "                                                 IDCol='PassengerId',\n",
    "                                                 fDrop=fDrop)\n",
    "\n",
    "testDataL, _, _ , testData = prepLGB(test,\n",
    "                                 classCol='Survived',\n",
    "                                 IDCol='PassengerId',\n",
    "                                 fDrop=fDrop)\n",
    "\n",
    "# Prepare data set using all the training data\n",
    "allTrainDataL, allTrainLabels, _ , allTrainData = prepLGB(train,\n",
    "                                                 classCol='Survived',\n",
    "                                                 IDCol='PassengerId',\n",
    "                                                 fDrop=fDrop)\n",
    "\n",
    "# Set params\n",
    "# Scores ~0.784 (without tuning and early stopping)\n",
    "params = {'boosting_type': 'gbdt',\n",
    "          'max_depth' : -1,\n",
    "          'objective': 'binary',\n",
    "          'nthread': 3, # Updated from nthread\n",
    "          'num_leaves': 64,\n",
    "          'learning_rate': 0.05,\n",
    "          'max_bin': 512,\n",
    "          'subsample_for_bin': 200,\n",
    "          'subsample': 1,\n",
    "          'subsample_freq': 1,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'reg_alpha': 5,\n",
    "          'reg_lambda': 10,\n",
    "          'min_split_gain': 0.5,\n",
    "          'min_child_weight': 1,\n",
    "          'min_child_samples': 5,\n",
    "          'scale_pos_weight': 1,\n",
    "          'num_class' : 1,\n",
    "          'metric' : 'binary_error'}\n",
    "\n",
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.005],\n",
    "    'n_estimators': [40],\n",
    "    'num_leaves': [6,8,12,16],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'random_state' : [501], # Updated from 'seed'\n",
    "    'colsample_bytree' : [0.65, 0.66],\n",
    "    'subsample' : [0.7,0.75],\n",
    "    'reg_alpha' : [1,1.2],\n",
    "    'reg_lambda' : [1,1.2,1.4],\n",
    "    }\n",
    "\n",
    "# Create classifier to use. Note that parameters have to be input manually\n",
    "# not as a dict!\n",
    "mdl = lgb.LGBMClassifier(boosting_type= 'gbdt',\n",
    "          objective = 'binary',\n",
    "          n_jobs = 3, # Updated from 'nthread'\n",
    "          silent = True,\n",
    "          max_depth = params['max_depth'],\n",
    "          max_bin = params['max_bin'],\n",
    "          subsample_for_bin = params['subsample_for_bin'],\n",
    "          subsample = params['subsample'],\n",
    "          subsample_freq = params['subsample_freq'],\n",
    "          min_split_gain = params['min_split_gain'],\n",
    "          min_child_weight = params['min_child_weight'],\n",
    "          min_child_samples = params['min_child_samples'],\n",
    "          scale_pos_weight = params['scale_pos_weight'])\n",
    "\n",
    "# To view the default model params:\n",
    "mdl.get_params().keys()\n",
    "\n",
    "# Create the grid\n",
    "grid = GridSearchCV(mdl, gridParams,\n",
    "                    verbose=0,\n",
    "                    cv=4,\n",
    "                    n_jobs=2)\n",
    "# Run the grid\n",
    "grid.fit(allTrainData, allTrainLabels)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# Using parameters already set above, replace in the best from the grid search\n",
    "params['colsample_bytree'] = grid.best_params_['colsample_bytree']\n",
    "params['learning_rate'] = grid.best_params_['learning_rate']\n",
    "# params['max_bin'] = grid.best_params_['max_bin']\n",
    "params['num_leaves'] = grid.best_params_['num_leaves']\n",
    "params['reg_alpha'] = grid.best_params_['reg_alpha']\n",
    "params['reg_lambda'] = grid.best_params_['reg_lambda']\n",
    "params['subsample'] = grid.best_params_['subsample']\n",
    "# params['subsample_for_bin'] = grid.best_params_['subsample_for_bin']\n",
    "\n",
    "print('Fitting with params: ')\n",
    "print(params)\n",
    "\n",
    "# Kit k models with early-stopping on different training/validation splits\n",
    "k = 4\n",
    "predsValid = 0\n",
    "predsTrain = 0\n",
    "predsTest = 0\n",
    "for i in range(0, k):\n",
    "    print('Fitting model', k)\n",
    "\n",
    "    # Prepare the data set for fold\n",
    "    trainData, validData = train_test_split(train,\n",
    "                                            test_size=0.4,\n",
    "                                            stratify=train.Survived)\n",
    "    trainDataL, trainLabels, trainIDs, trainData = prepLGB(trainData,\n",
    "                                                     classCol='Survived',\n",
    "                                                     IDCol='PassengerId',\n",
    "                                                     fDrop=fDrop)\n",
    "    validDataL, validLabels, validIDs, validData = prepLGB(validData,\n",
    "                                                     classCol='Survived',\n",
    "                                                     IDCol='PassengerId',\n",
    "                                                     fDrop=fDrop)\n",
    "    # Train\n",
    "    gbm = lgb.train(params,\n",
    "                    trainDataL,\n",
    "                    100000,\n",
    "                    valid_sets=[trainDataL, validDataL],\n",
    "                    early_stopping_rounds=50,\n",
    "                    verbose_eval=4)\n",
    "\n",
    "    # Plot importance\n",
    "    lgb.plot_importance(gbm)\n",
    "    plt.show()\n",
    "\n",
    "    # Predict\n",
    "    predsValid += gbm.predict(validData,\n",
    "                              num_iteration=gbm.best_iteration)/k\n",
    "    predsTrain += gbm.predict(trainData,\n",
    "                              num_iteration=gbm.best_iteration)/k\n",
    "    predsTest += gbm.predict(testData,\n",
    "                             num_iteration=gbm.best_iteration)/k\n",
    "\n",
    "# Print assessment\n",
    "# assessMod(predsTrain, trainLabels, predsValid=predsValid, yValid= validLabels,\n",
    "#           report=True, plot=True)\n",
    "\n",
    "# Save submission\n",
    "sub = pd.DataFrame()\n",
    "sub['PassengerId'] = test['PassengerId']\n",
    "sub['Survived'] = np.int32(predsTest > 0.5)\n",
    "sub.to_csv('sub2.csv', index=False)"
   ]
  }
 ]
}